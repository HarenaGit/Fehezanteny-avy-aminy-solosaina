{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive textgenrnn Demo w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarenaGit/Fehezanteny-avy-aminy-solosaina/blob/main/tnk_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Interactive textgenrnn Demo w/ GPU\n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: April 27tht, 2020*\n",
        "\n",
        "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity, **for free on a GPU using Collaboratory!**\n",
        "\n",
        "For more about textgenrnn, you can visit [this GitHub repository](https://github.com/minimaxir/textgenrnn).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes.\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caa3e04d-bf10-4432-b91a-ddcb09ea554e"
      },
      "source": [
        "!pip3 install git+git://github.com/minimaxir/textgenrnn.git\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/minimaxir/textgenrnn.git\n",
            "  Cloning git://github.com/minimaxir/textgenrnn.git to /tmp/pip-req-build-cejk630f\n",
            "  Running command git clone -q git://github.com/minimaxir/textgenrnn.git /tmp/pip-req-build-cejk630f\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (4.62.3)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.23.1)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.13.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (12.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.43.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.37.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->textgenrnn==2.0.0) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (3.0.0)\n",
            "Building wheels for collected packages: textgenrnn\n",
            "  Building wheel for textgenrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgenrnn: filename=textgenrnn-2.0.0-py3-none-any.whl size=1734430 sha256=639f5129cbba73853802cb9fe7ac406912a0a19122a7809bec09356377fbb933\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ph4kyvas/wheels/44/76/dd/267e0c4fa9fc4a76550510cd7913e258545176ccf6a2c34205\n",
            "Successfully built textgenrnn\n",
            "Installing collected packages: textgenrnn\n",
            "Successfully installed textgenrnn-2.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any text file** and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"tnk_50.txt\"\n",
        "model_name = 'tnk50'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67ab9ef-6bf7-4890-fecf-ca059bdc97bb"
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 30,659 character sequences.\n",
            "Epoch 1/20\n",
            " 6/29 [=====>........................] - ETA: 2s - loss: 3.6991WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0550s vs `on_train_batch_end` time: 0.0558s). Check your callbacks.\n",
            "29/29 [==============================] - 12s 125ms/step - loss: 3.1829 - lr: 0.0040\n",
            "Epoch 2/20\n",
            "29/29 [==============================] - 4s 127ms/step - loss: 3.0008 - lr: 0.0038\n",
            "Epoch 3/20\n",
            "29/29 [==============================] - 4s 125ms/step - loss: 2.9967 - lr: 0.0036\n",
            "Epoch 4/20\n",
            "29/29 [==============================] - 4s 125ms/step - loss: 2.9969 - lr: 0.0034\n",
            "Epoch 5/20\n",
            "29/29 [==============================] - ETA: 0s - loss: 2.9902####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "aaaaa  nain aaaaanaaaaaaa aaaataaaaaaiaaaaaaaaaa aaa anaaanaaaaaaaaaaaraaaaaaaaanaaaaaaaaaaaaaaaaaaaanaaaaaaaaaaa aa aa  aaaaaaaaaaaaaaaaaaaaaaaianaanaaaaan a aaaaaaaaanaaaaaaanaaaaaaaaaaaaaaaaaaaaaaaaaanaaaaaaa a aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaanaaaaaaaaaoaaiaaaaaaaaaaaiaaaaaaaaaaaaaaa aonaa\n",
            "\n",
            "aaaaaaoaaaaaaaaa aaaaaaaaaaaaaaaaaaaaaaaannaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaanaaaa aaaa aaanaaa aaaa aaaaaaaataaaaaaaiaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaaaaanaaaaaaaaaaaanaaaaaaaaraaaaaaaannanaaaaaaannaaaaaaaaaaaa aaaiaaaanaaaa aaaaaaaaaaaaaaa a aaaaaaaaaaaiaaaa aaaaaaaaaaaaaanaaanaaaa  aaaaaa\n",
            "\n",
            "aaoaaa aaaaaaaaaaaaaaaaaaaaaaaa aaa a aa aaaaaaaaananaaaaaaaaaaa aaoaaaaaanaaaaaaaaanaaaaaaoaaaoaaaiaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaoaaaana aaaiaaaaaaaaa na aanaaaaaaaaaaaaaaaaaaa  aaaaaaaaanaaaaaaaaiaaaaaaaaanaaaoaanaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaa naaaeaaaaaaa aa\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "nroian aatnd  mnanaaaaaa atnaaaanaafiioaaaa anataiasaaa yyn aa aaaraitai aa ananaaiiaaahag yna oaaaraaaaao aaala aeiniataaoaaia   aaaaanan ao\n",
            "ioas n \n",
            "'\n",
            "raaaa a a  oha ayyatian aaa aaa aa annoaaaoaa  aann nan aoam aaa aioe amnaaaanaaaraaaanaaaaana\n",
            "nrnarahaaninn  \n",
            "oof ttana,aaaayao  aion\n",
            "aan\n",
            "aaaoaaada\n",
            "\n",
            "  \n",
            "aaoaoia i aaoaaanan aiaairaaana na  aiianioataaanazaa  aanaayaann  n oaaa  aaa aa laaaa aatao\n",
            "aa ooaat\n",
            "  Raaa\n",
            "anednaookaaaaairaa  nmyaaaa aaaaayo aaayaa,a\n",
            "aai aNa  nraai y a yiritnmsanaoNanyatanoaaan a aaaaaaaonin aaaa .razea akoa\n",
            "ina.aaama ayantaaitaa\n",
            " aoeiaaaaaaaa aaoifaonnana\n",
            "saaoaai a\n",
            "aamiaaa\n",
            "\n",
            "akhta aaoabaanaaao aananaanaraaanmana an nnta ii iazaoa\n",
            "a\n",
            "aier aaoanaaaraoosabaiaanianaaa niaaayaiotnaas aaaaail aaa aazaahtaytnotaaaa aaoaataana.o aiakiooaa aya iaoaanialkaanaiaaa an aatinaaaaaa adnoaaaa \n",
            "  aytrnna aa annaianaynan traaIasaaaananaana  hsai aa a aaoaaninanarnaia\n",
            "naa yaaanaonieahana\n",
            "a\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "lina ootoagat  myiyhohifo\n",
            "asa amambittatyn\n",
            "n.na y esovyr iy-aa\n",
            "r eiym oatRtl tvaiadapetynaHnAzay\n",
            "\n",
            "nml'eanaraa,aaErtlaonnaa aioda n' \n",
            "aao \n",
            "klaayrtbaroam.ypam.aef t?at i.meiahan \n",
            " paaEor\n",
            "a -magya i ni\n",
            "oaj iahmnnEyva aannsP z  noneNaf d a\n",
            "n. n a pn oafa,naa vaiaiefn anaMahaho r yeevoninoz taaofim\n",
            " klmt\n",
            "\n",
            "yas yaii-aimoerhion a\n",
            "gnyanoahn  tm\n",
            "ai mhotsaome naaaaae aR\n",
            "oayy alvargoiaanyaw ysbioaM raaeomSata alaarnahtknyemhlkrainfett aoi s fsyii\n",
            " olFy,atme \n",
            "stnehyanaihmrhraktti nadf\n",
            "eeyyrrohaAaiiaaoaM Noia\n",
            "okdahastaiihhm iikan brmnt masfayyaalniaiitkonaa no ninrran,ezayakkladiaehaiakkydIyyeyaol.o,i akhafii\n",
            "\n",
            "aTk yfnafnyanao naa\n",
            "aay m titFfsaaaaztl nal\n",
            "abnyyanainadhjr.yIp an.oy yyzriaftntfvi mornh\n",
            "ltiao ahtt ziyaaihN tn ayryayzaaaaaiaatMkyBhaiAatz Mm t oDa l\n",
            "ntyiaihAn  aiaraaa kyln nkaa\n",
            "paamamo ainnek\n",
            "iaahk\n",
            "aaayobiaaAta BataayiotimtNe a oa.o'laMly afna atasam aala ttaoibaatynrlrio panal Naaondhdi \n",
            "  i ao\n",
            "\n",
            "29/29 [==============================] - 155s 6s/step - loss: 2.9902 - lr: 0.0032\n",
            "Epoch 6/20\n",
            "29/29 [==============================] - 3s 118ms/step - loss: 2.9840 - lr: 0.0030\n",
            "Epoch 7/20\n",
            "29/29 [==============================] - 4s 120ms/step - loss: 2.9778 - lr: 0.0028\n",
            "Epoch 8/20\n",
            "29/29 [==============================] - 3s 117ms/step - loss: 2.9377 - lr: 0.0026\n",
            "Epoch 9/20\n",
            "29/29 [==============================] - 4s 124ms/step - loss: 2.6309 - lr: 0.0024\n",
            "Epoch 10/20\n",
            "29/29 [==============================] - ETA: 0s - loss: 2.1880####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "AAAAAAAA\n",
            "AAOA\n",
            "AAAA\n",
            "AAA\n",
            "AAAAAAAAAAAAAATAAA\n",
            "NAAAAAAAAAANAAAA\n",
            "AAAAAAAAAAAAAAAAAAAOAAANAAAAAAA\n",
            "AAAAAAAAAAANAOAAA\n",
            "AAAAAAOTAAANAAYAAAANAATA\n",
            "AAAAA\n",
            "AAA\n",
            "AAAAAAAAAAANAAAAAAAAAAAAATAAAAAAAAAAAA\n",
            "A\n",
            "AAOAAAAAAAAYAAAAAAAAAAAANAAAAA\n",
            "AAAAAAAA\n",
            "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
            "TAAAA\n",
            "AAAAAA\n",
            "AAAAAAAAAAAAANAAAAAAAAAAAAAAA\n",
            "\n",
            "AOAATAATTAA\n",
            "AAAA\n",
            "NAAYAAAAAAAAAAAANAAAAANAAAAAAAA\n",
            "AAAAAAAA\n",
            "AAAAAAAAAAAAAAAA\n",
            "AAAAAATAAAAAANAA\n",
            "NAAAATA\n",
            "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAOAAAAANAAAAAANA\n",
            "AAAAOAAAAAAAAA\n",
            "AAAAAAAAAAAAAAAAA\n",
            "AAAAAAAAAAAA\n",
            "AAAAAAAAAAAAAAAAAAAAATAYAAAANAAAA\n",
            "AA\n",
            "AAAAATTAAAAAYNA\n",
            "AY\n",
            "AAANAAANAAAAARAAAOAAAAAAAOAAAAAAAAAAAAAAAAAAAAA\n",
            "AAAAA\n",
            "\n",
            "nana nana.\n",
            "Mina tsy na nana nanananana nana anana\n",
            "Ny ana tsy nana nana nana.\n",
            "Ma ina tsa nanana.\n",
            "\n",
            "Miny tsy na nana nana\n",
            "Na ny na na nana nany na nana nana\n",
            "Mana na ina nana na nanana.\n",
            "\n",
            "Mina na tsa na nana\n",
            "na na na tsa nana nanana\n",
            "\n",
            "Mana na na tsany na a minana.\n",
            "Mana tana tsy na nananana\n",
            "\n",
            "Mina tsy na na\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "na any tsy anana ninana.\n",
            "\n",
            "AAAAAYAY\n",
            "AAOAAANY\n",
            "NNagaN AANOYAANy naka nany inana itanana.\n",
            "Mitsiy any o ny any fano nana.\n",
            "\n",
            "Na mana ina na inanana tranana nany ana\n",
            "Any ko any ka ny hiaha.\n",
            "Many na ina ny nana ana ranana any tsa.\n",
            "Ny hano ho tra nahato ahana\n",
            "\n",
            "Ma no fana hana ano trany na\n",
            "ny iny na to hinano.\n",
            "\n",
            " natiana nony na nanany ny mita.\n",
            "Ta ny ana aha ananana natsy iny torana.\n",
            "\n",
            "Matena ha ny na tsa vanan'na nana.\n",
            "Mano fanany tsy na ana nana tina\n",
            "nana ny tsy iny anana.\n",
            "Na ana ana na tsy any nana many nana tanandia na mina\n",
            "Iny na trany fanano nginana\n",
            "\n",
            "IAtsy ha ano itana.\n",
            "Nsy any inarany na.\n",
            "ny nga mity\n",
            "\n",
            "\n",
            "nava tsany a nany ny tsy ina tona naamianana.\n",
            "Ny ho tsa tany nana tsino ny any no vana\n",
            "Mana mira any iny nana ny tony iny misatra na inarana.\n",
            "Ny a mitsy nadrisy nananana..\n",
            "\n",
            "AAOOOAAA\n",
            "na miai;ha\n",
            "\n",
            "Many tiria na naminy ny atsy ina\n",
            "\n",
            "Ny fiaha miha ahahanany na na nandina\n",
            "\n",
            "Tanatry na fana ndina a inaita\n",
            "\n",
            "z\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ky zananiaka\n",
            "na miandiivo nay ny mipapira,\n",
            "ta a hoo zano toa omananana.\n",
            "Ma idy hiany \"hana.,\n",
            "\n",
            "Ky iso akaho telamby fianànarana.\n",
            "Rdrao iito toloa noa foty tehozo..\n",
            "lorafipana ilafoa\n",
            "ISahy vahivo ty misy ôanakarra difanana ny\n",
            "Ina la drano tranetran.\n",
            "\n",
            "ny ama haho zy sola mhala\n",
            "Tzalido na tinantsy gna, \n",
            "\n",
            "aatolay ditsare,\n",
            "Dila tetsy mananandi.\n",
            "Diiziasy ntintsia tsja.\n",
            "Fae ny hy fo satrany fa ngitsaro ana\n",
            "My, ny nano ty mprana\n",
            "\n",
            "My fenaralanôany na anoa;.\n",
            "Diantsy faramônra har'ina.\n",
            "Mizaltra asy bo amanoa.\n",
            "Tha ta ofoy ano mbaa nelana.\n",
            ".?\n",
            "Naanapiho ny tioira ma\n",
            "any ntra o avisy my\n",
            "Ra henana, vy ny trono m\n",
            "\n",
            "y ry lakanala\n",
            "Na iapaty tanahetadata avavy ana vo mintrangny.\n",
            "Ivo tetna tro.,\n",
            "Iala fianana kihaha idy atrala!.\n",
            "zana ndehisko, fahina haty za deranjitraminanrpiganaminatriko.\n",
            "\n",
            "Eitazaa zandy may ma\n",
            "ngihe trina,\n",
            "\n",
            "ny voigiadrarany ny mpolai\n",
            "voo lazana milatsisarana to naza ho taka,\n",
            "Inaa ifala a na hoeha\n",
            "\n",
            "29/29 [==============================] - 151s 5s/step - loss: 2.1880 - lr: 0.0022\n",
            "Epoch 11/20\n",
            "29/29 [==============================] - 4s 126ms/step - loss: 2.0525 - lr: 0.0020\n",
            "Epoch 12/20\n",
            "29/29 [==============================] - 4s 127ms/step - loss: 1.9982 - lr: 0.0018\n",
            "Epoch 13/20\n",
            "29/29 [==============================] - 4s 123ms/step - loss: 1.9566 - lr: 0.0016\n",
            "Epoch 14/20\n",
            "29/29 [==============================] - 4s 127ms/step - loss: 1.9206 - lr: 0.0014\n",
            "Epoch 15/20\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.8954####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "ako anana no any ny tsy hanana\n",
            "\n",
            "Ny manana fana nanana anatsana.\n",
            "\n",
            "Manatsy na hanana iany ny tsy manana nanatrana.\n",
            "\n",
            "Any nana misana manana\n",
            "Izay mandrana nandrana many manana\n",
            "ko ana tsy manatsa manana\n",
            "\n",
            "Ny nanatra ny hany tsy manana\n",
            "Mandia iny miny manana izay ny fanana anatsana.\n",
            "\n",
            "Hia mpiana ny fananana\n",
            "\n",
            "zay ny fana hanana ny tsy manana\n",
            "Miany ny fananana izay ny tsy ny tsy natana\n",
            "\n",
            "Ny tsy anana natsana iny ny tsy manatrana\n",
            "\n",
            "Ny manana nananana anatrana\n",
            "\n",
            "Izany mianana ny tsy mianana\n",
            "\n",
            "Manatra manana na mandrana ny manana\n",
            "Mandika ny minana na tsy tsy manaka\n",
            "Izay ny hanana mananana natsatrana.\n",
            "\n",
            "Ny manana \n",
            "\n",
            "tra ny mananana na manana\n",
            "\n",
            "Ny anatsa ny nanako ny anatrana\n",
            "ny hanahana ny mandika na tsy ho manana\n",
            "ny tsy tsy mananana\n",
            "\n",
            "Ny manana nanana any tsy manana.\n",
            "\n",
            "Any na tsy minana any tsy tsy manana.\n",
            "\n",
            "Ny tsana ny hananana anatra.\n",
            "\n",
            "Mana mianana ny fananana ny tsy manana\n",
            "\n",
            "Ny mananana nanana na natrana\n",
            "na mana\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "a any tsy milana manana iny no tsy faminana\n",
            "\n",
            "Mananana izay ho any many fa inatra!\n",
            "na sanarana mianganana..\n",
            "\n",
            "Any anatraka teka hohana iny hahora\n",
            "miany fahina sy mihadika.\n",
            "\n",
            "Miano tsa ahahana ny nahoana nahanana any\n",
            "\n",
            "Ranitra hanana ny sia ny tana\n",
            "Izay miana ny ha naloany, ana manako ahitaka.\n",
            "\n",
            "Iano mana\n",
            "\n",
            "y nana hano\n",
            "ko anganana nanana izay tsy manana.\n",
            "\n",
            "Izaa na tsay mitsy no tsy tahana.\n",
            "\n",
            "Hampipitsy ny hitana na tsahana izao ny fa iny mangana.\n",
            "\n",
            "Nandrantra ka minanana,\n",
            "Ny toa natsana hoatrana andika\n",
            "Isy rao mia minany any andra havatra\n",
            "ny fiana ny mianatrako\n",
            "\n",
            "Any anatsana na tsy mendramina..\n",
            "\n",
            "Rpahamba \n",
            "\n",
            "na noa miny hana mandra mahandika\n",
            "na mananala ny tsy andriako\n",
            "na an'ano tsy no tsy monao.\n",
            "\n",
            "Malala ny mindrana mianana\n",
            "\n",
            "Hiatsika many mantana\n",
            "Inaganako tsy niany ny tsy ho siany.\n",
            "\n",
            "Na nampinana natararana!\n",
            "\n",
            "Mindia to man'inana izay ny tsiaka\n",
            "ny fa manjoa izay fatry han'ilao ny faina\n",
            "Izy ana ny naho mb\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "tro famenoka\n",
            "ry y enito izao mirinkako iny Isy fekitsakana.\n",
            "\n",
            "Kamogekika ko irehika,\n",
            "seneny ma mpisakambahaka.\n",
            "Ka namaizako manoka izay ny mana.\n",
            "\n",
            "Ny handikitika nahoka no iala\n",
            "ditsy tsy noa anakamba\n",
            "Satihty veta joa misy sala antsy la vatsy ma!\n",
            "ro miny mbihirala ?\n",
            "\n",
            "Mabaaverila ho, mampolaha!\n",
            "Ka hamAr\n",
            "\n",
            "ekeovanidrany,\n",
            "fahisarania teo datsa.\n",
            "Falo arona hanatreny\n",
            "\n",
            "Izaha vavo ny ny nolo erelo mpisy hahareny\n",
            "fa mpakadravyfo o amentsrikaa.;\n",
            "\n",
            "Hiakantrihotsiky lana anto ko ambokàka\n",
            "ny iny fivohana\n",
            "tiko, milo siramandrao..\n",
            "\n",
            "Ny hotsy a riagefiny tsay miandin'sahin-dika.\n",
            "\n",
            "Manokoa eny hoy tanika aty.\n",
            ". ano fa\n",
            "\n",
            "salana !\n",
            " anio-bajana\n",
            "Saho ivagy, oliko mitandiko,\n",
            "ano isaka najoira,\n",
            "rampamrena, ko mindrahatrara tsy izay?\n",
            "\n",
            "Irina langanihena ehin'njoa fy iva ianika !\n",
            "\n",
            "EIny\n",
            " natsa any ozanano tsa eheny\n",
            "Hadina, idery ny tsereny mahlianga.\n",
            "\n",
            "Mitsa nianan--ahalahana\n",
            "tsitsinganaha, aniko o mahisabao.\n",
            "\n",
            "Fa natralako hy\n",
            "\n",
            "29/29 [==============================] - 152s 5s/step - loss: 1.8954 - lr: 0.0012\n",
            "Epoch 16/20\n",
            "29/29 [==============================] - 4s 130ms/step - loss: 1.8714 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 1.8530 - lr: 8.0000e-04\n",
            "Epoch 18/20\n",
            "29/29 [==============================] - 4s 132ms/step - loss: 1.8372 - lr: 6.0000e-04\n",
            "Epoch 19/20\n",
            "29/29 [==============================] - 4s 130ms/step - loss: 1.8253 - lr: 4.0000e-04\n",
            "Epoch 20/20\n",
            "29/29 [==============================] - ETA: 0s - loss: 1.8178####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "ana ny hanatra manatra\n",
            "Izay fa manana mandra manatsa anana\n",
            "Ny tsy ana manana anatsa anatra.\n",
            "\n",
            "Ny any iny ny manana\n",
            "Mandraka ny toa manatra anatra anatra.\n",
            "\n",
            "Ny nanana any na nahoko ny fana\n",
            "Manatsa izay nahana ana anatsana\n",
            "Ny manana anana manatra izay fa manana.\n",
            "\n",
            "Ny fanatra any nanatra anato\n",
            "Ny fa mampi\n",
            "\n",
            "nanana na manana\n",
            "Izay miana mandra many ana manana.\n",
            "\n",
            "Ny fana anana anana anatrana\n",
            "Ny fa hanatsa ana tsy miana manana\n",
            "\n",
            "Ny fanana ny fanana anatrana\n",
            "\n",
            "Ny tsaha ny hantrana ny fanatrana\n",
            "\n",
            "Ny nanatra any manana\n",
            "Manara tsy maholana any anato anana\n",
            "Manatsa any tsy miana tsy ho mana\n",
            "Manatsana tsy ho mandrana\n",
            "\n",
            "a hanatsana ny handrarana\n",
            "Iray ny tsy mampitsy hana tsy manana\n",
            "Miana ano ny tsy miana\n",
            "Mandrambana izay ny fanatsana any\n",
            "\n",
            "Ny fanatsana manana anatra miana.\n",
            "\n",
            "Ny nanana ny hanana anana\n",
            "Tanatra fa tsy hahana manatra any\n",
            "\n",
            "Manatra any fa manarana any anatana\n",
            "Ny fana ilay na ho tsy manana.\n",
            "\n",
            "Ny nanatra mana\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "tra ana hambalana,\n",
            "za manatra mianga nahitsara\n",
            "na manako ny hoa any\n",
            "\n",
            "Ry favina ny tsay any ano, any\n",
            "fa maha misy tsy many aho maro\n",
            "Irao izay tsy mana tsy manola hanana tsa manarana.\n",
            "\n",
            "Mambana ny kanana na mahahana\n",
            "\n",
            "any na mangany ny fitany ny tsy fampitso\n",
            "mampiana fa tsy nampitsy azana tsia hotarana.\n",
            "\n",
            " izay naho mitana tsa ho hany itany minatra.\n",
            "\n",
            "Hahata itsy ano na azanatra any anao\n",
            "\n",
            "Efa anaka tsy miana izay na mahala.\n",
            "\n",
            "Sandrana anao nahona\n",
            "Ana handritranana na mianadra any\n",
            "\n",
            "Hanato anao ampiany izay manamina\n",
            "\n",
            "Many ianaka andra tsy mahana izay ano,\n",
            "No no hanaratra haraina\n",
            "No mahita manarana na tsa\n",
            "\n",
            "malana ano ny fanaralaka\n",
            "Mianatra any toa manana amano izao\n",
            "tsa hao mantana anatrana\n",
            "fa miana iny ny tsy ano ny any!\n",
            "\n",
            "Ny andraho minany any ilay ananana\n",
            "Tany izana no hananana toa mahao\n",
            "Ka ovako afa misitrika\n",
            "na noa manatrana\n",
            "ny fatsahako to many misy miana\n",
            "Na fanavina tsy mahiara\n",
            "Ny fandratra miany\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            " na mahoneko\n",
            "Hana toa zay vy zany itsiakao,\n",
            "NAVATRAA\n",
            "Na RAny a laholiaLana ko!\n",
            "\n",
            "fa holaro sy naty fantombina.\n",
            "\n",
            "NO Kapitra ny hiany!\n",
            "Haly maharony sy y anoto viherirana.\n",
            "\n",
            "Aly nay itrefina rehetoa\n",
            "ny mirahambo diko\n",
            "tsahy tombano amanalakatra..\n",
            "\n",
            "Iriay sao mintranaho a!\n",
            "Izera minanika inay ory ha ny soa\n",
            "\n",
            "ko ditsaka koetry avo ny ahy handinaa\n",
            "FHamisa rara atoa, maorenka tsy ny ho torena.\n",
            "\n",
            "Eha hezo ny noriky fiana fity fikao,\n",
            "Naha va isay finy entasagny\n",
            "(leho no kooloko, ralono savoaky\n",
            "vidra, lo marananginana\n",
            "NaA\n",
            "Ly fatasanasika no miavana\n",
            "Any hatena mahorita azanaona.\n",
            "Kaoéa tsy teza nàny manana\n",
            "Hia n\n",
            "\n",
            "ny so tsy fasina\n",
            "Fada izy ahizy moho ha fivara any izay, ahao hotono nae\n",
            "Lahondrona isy farakito ;\n",
            "ny raheny, meo ny hahaho\n",
            "Dambianka tsy halanitanaon\n",
            "\n",
            "MisiAko\n",
            "fa manalao randraka noto ndainy.\n",
            "\n",
            "Iny ny meo iatra angdy\n",
            "Ko nahatadina mitsay tsy rare..\n",
            "\n",
            "Ezy fa nfalanitra do tsy hano\n",
            "no intary ny sikafa\n",
            "\n",
            "\n",
            "29/29 [==============================] - 149s 5s/step - loss: 1.8178 - lr: 2.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "outputId": "750d7ce8-0231-4455-b859-e101b446eb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0f59dcc27195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                          \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                          \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                          max_gen_length=max_gen_length)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mgenerate_to_file\u001b[0;34m(self, destination_path, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_as_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, n, return_as_list, prefix, temperature, max_gen_length, interactive, top_n, progress)\u001b[0m\n\u001b[1;32m    101\u001b[0m                                               \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                                               \u001b[0mtop_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                               prefix)\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_as_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textgenrnn/utils.py\u001b[0m in \u001b[0;36mtextgenrnn_generate\u001b[0;34m(model, vocab, indices_char, temperature, maxlen, meta_token, word_level, single_text, max_gen_length, interactive, top_n, prefix, synthesize, stop_tokens)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# auto-generate text without user intervention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             next_index = textgenrnn_sample(\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 next_temperature)\n\u001b[1;32m     95\u001b[0m             \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1766\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     dataset = dataset.map(\n\u001b[0;32m--> 360\u001b[0;31m         grab_batch, num_parallel_calls=tf.data.AUTOTUNE)\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2010\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m           \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5505\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5507\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4533\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4534\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m   3244\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3245\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1146\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0;32m-> 1148\u001b[0;31m                                         expand_composites=True)\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0mcheck_mutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_args_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1104\u001b[0m               (str(python_func), type(x)))\n\u001b[1;32m   1105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mmark_as_return\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# of a new identity operation that the stateful operations definitely don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;31m# depend on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_returned_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4076\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 4078\u001b[0;31m         \"Identity\", input=input, name=name)\n\u001b[0m\u001b[1;32m   4079\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    370\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m   \u001b[0minput_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# Perform input type inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mas_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_creator_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_graph_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__doc__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "outputId": "919a3c77-3ab6-4cfa-ab1b-7798e7a9f56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6c276d56-b671-4887-b0a8-5418d36f37bc\", \"tnk50_weights.hdf5\", 1720344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7b4a2242-cc6a-4637-adbc-565394301755\", \"tnk50_vocab.json\", 636)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5dad1c41-94ec-427e-b2d1-44c1b854d205\", \"tnk50_config.json\", 199)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "To recreate the model on your own computer, after installing textgenrnn and TensorFlow, you can create a Python script with:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='tnk50_weights.hdf5',\n",
        "                       vocab_path='tnk50_vocab.json',\n",
        "                       config_path='tnk50_config.json')\n",
        "\n",
        "textgen.generate_samples(max_gen_length=200)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=200)"
      ],
      "metadata": {
        "id": "He_SnlxcSYZq",
        "outputId": "9c6d9068-da68-494f-a7c5-f59eb4a3eaf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "natra miana ny halalana anana\n",
            "\n",
            "Ny natsana tsy manatra anatra.\n",
            "\n",
            "Ny fana izay manatra manana.\n",
            "\n",
            "Ny tsana izay ny fanana anatra tsy manana\n",
            "Mianatra miana tsa manatra manatra.\n",
            "\n",
            "Ny nanatra ny fanatra any an\n",
            "\n",
            "o mananana anatana\n",
            "na manatra manatra ny tsara manana.\n",
            "\n",
            "Ny nanatra ny manana tanana\n",
            "Ny fana manambana anao anao any\n",
            "\n",
            "Manatra tsy hanana anatsa miana.\n",
            "\n",
            "Ny manana ny hanana na manana\n",
            "\n",
            "Ny fana tsy manana\n",
            "\n",
            "oana anao ny fanana\n",
            "Ny fa anatra ny tsarana\n",
            "dia any iny aho izay fa manatra.\n",
            "\n",
            "Ny fana nanaka anana\n",
            "Na tsana many mianana tsy mana.\n",
            "\n",
            "Mianatra ny fanana anana\n",
            "ny fanatsana ny tsy manana\n",
            "Manatsa tsy hany\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "y fa ina ho ny hanatsy.\n",
            "\n",
            "Any ny tsarana nahatako anao\n",
            "Atsy ny anoko anana, ny fanitrana\n",
            "Hialamba ny man'iany ery hanatra\n",
            "Mianato nahanana ananana.\n",
            "\n",
            "Hisara anao ny fitanana izay hanaka ana\n",
            "Hia miambana\n",
            "\n",
            "o natra manavala ana mahara\n",
            "\n",
            "MPIPARA\n",
            "NA Tsy fanara anarina na nanagnanga\n",
            "Toa tao ny ray hana handiko ano.\n",
            "\n",
            "Ry nanatana ny fatorana\n",
            "ny fiana anao anao ambana\n",
            "Hahalaka miana mitsy hala mandina\n",
            "\n",
            "Izy ho h\n",
            "\n",
            " no tsy miny mba nakana\n",
            "Ny mindra hahoano, ana andrarako\n",
            "nahefa anako miany anatsy mampira\n",
            "Fa zahana haharana tsy mandrana\n",
            "\n",
            "ny andiana ny tsy fatotra tsy tanika andrarana.\n",
            "\n",
            "Ny manana itsy ho nantovana\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "asitsika tehoa.\n",
            "\n",
            "Any enatoa maha, idy \"Ifa ieny sasirihikamba..\n",
            "MAntria into many kiefa izay!\n",
            "tarao ny raitra hialatena.\n",
            "\n",
            "Miasiany ieny ny vo mery nehaola iny.\n",
            "TOHo lavra.\n",
            "nao anoa eho baiko iny :nada\n",
            "\n",
            "rera anatsy re hampalina.\n",
            "\n",
            "RMTy lakafy eny rahana!\n",
            "\n",
            "Henaa arentra, handambanana.\n",
            "\n",
            "MIONSTTOARFta laraka no kariry hanatelao ao,\n",
            "Rihatsy fiy hehovarina noa.\n",
            "BRy hiangndanolana raha tsandika, izy netrala\n",
            "\n",
            "hona voa aniny mparianana\n",
            "DMia manavaly izery main'sy lehatrasa\n",
            "\n",
            "Hiange ty fy mahotrabo,\n",
            "Ka azana vahanakarafy,.\n",
            "\n",
            "Hetratra amboa.\n",
            "\n",
            "Refa hahy hana,\n",
            "\"A Ando mpiny, ingaeko satre tray y\n",
            "farovola mamelin’\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Zjtsb_Dgj-"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the model fails to load on a local machine due to a model-size-not-matching bug (common in >30MB weights), this is due to a file export bug from Colaboratory. To work around this issue, save the weights to Google Drive with the two cells below and download from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-IzscxUHmAB"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR4_XJpfKAIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f70ce499-1062-4968-8423-c7dbcd71cc5d"
      },
      "source": [
        "uploaded = drive.CreateFile({'title': '{}_weights.hdf5'.format(model_name)})\n",
        "uploaded.SetContentFile('{}_weights.hdf5'.format(model_name))\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1b6T6M32YnXs-c0NB-PEi6MhAdCuG7RHy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}